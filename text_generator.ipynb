{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generator\n",
    "\n",
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model, Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "### Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Size of the dataset: 107\nLength of Corpus: 1996490\n"
    }
   ],
   "source": [
    "filename = 'SV_works.txt'\n",
    "fileobject = open(filename)\n",
    "text = fileobject.read()\n",
    "lines = text.split('\\n')\n",
    "print('Size of the dataset: %d' %(len(lines)))\n",
    "print('Length of Corpus: %d' %(len(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making character sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 60\n",
    "text = text.lower()\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "No. of sequences:  665477\n"
    }
   ],
   "source": [
    "print('No. of sequences: ', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "No of unique characters: 59\n['\\n', ' ', '!', '\"', '$', \"'\", '(', ')', '+', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'â', 'æ', 'é', 'ê', 'ü', '—']\n"
    }
   ],
   "source": [
    "print('No of unique characters: %d' %(len(chars)))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indices = dict((char, chars.index(char)) for char in chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "Y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    Y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlstm_1 (LSTM)                (None, 128)               96256     \n_________________________________________________________________\ndense_1 (Dense)              (None, 59)                7611      \n=================================================================\nTotal params: 103,867\nTrainable params: 103,867\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "model.compile(optimizer=RMSprop(learning_rate=0.01), loss='categorical_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reweighted distribution generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nEpoch No: 1\n\n665477/665477 [==============================] - 463s 696us/sample - loss: 1.5398\n\n\n\n\n\nEpoch No: 2\n\n665477/665477 [==============================] - 462s 695us/sample - loss: 1.3468\n\n\n\n\n\nEpoch No: 3\n\n665477/665477 [==============================] - 458s 688us/sample - loss: 1.3106\n\n\n\n\n\nEpoch No: 4\n\n665477/665477 [==============================] - 463s 695us/sample - loss: 1.2924\n\n\n\n\n\nEpoch No: 5\n\n665477/665477 [==============================] - 462s 694us/sample - loss: 1.2802\n\n\t\t Generating text with seed: \"ciety there are stages of development. behind this epic ther\"\n\n\n\t\t Temperature:  0.2\nciety there are stages of development. behind this epic there is a man become the propers of the same suppose the self. the more and of the self? the more than the self. the possible and the self? when i am the same things and the same things and the state of the senses and the same possible and the same things and the same things and the same things the world is the possible and the same things and the same time and the more and the self. the world is the\n\n\t\t Temperature:  0.5\nciety there are stages of development. behind this epic there is and the soul is perception on the same different the things that it is and there is not fine more material wants to real of the man is in one of this world in the moon, and the real of the godand the fact of the problems that we general thought into the individual goodand consciously from thatthe mother is a philosophers, and when there willnever get to matter of the organs and we are the\n\n\t\t Temperature:  1.0\nciety there are stages of development. behind this epic there ao appersid to travelled we have been changed entire bind, because and ke own only behind it come from their universe. . gmost fight fergee. they, thou ar in rrpposest of the king was yoga claimed the world. this. so worship to thanmanifestation is there last bifter and have to conde, which, can insland thatcan be a contrume on it, how is all their great tich; love far thinkagd master? no etne\n\n\t\t Temperature:  1.2\nciety there are stages of development. behind this epic there come. comes only purity of my human childnes philosofs, will sayit miserya? entirefcited.when we came of human minds and all mind. igntinceter changing that we are conratety and proachomen, and all theee?\" therefore?\" \"has some gors man rushneds. down. i do not do these rametilly. while all crrease. on the becoming ullting as ruild the pody in bearrouse conaked or panestal. there will but than\n\nEpoch No: 6\n\n665477/665477 [==============================] - 463s 696us/sample - loss: 1.2699\n\n\n\n\n\nEpoch No: 7\n\n665477/665477 [==============================] - 461s 693us/sample - loss: 1.2656\n\n\n\n\n\nEpoch No: 8\n\n665477/665477 [==============================] - 462s 694us/sample - loss: 1.2595\n\n\n\n\n\nEpoch No: 9\n\n665477/665477 [==============================] - 463s 696us/sample - loss: 1.2563\n\n\n\n\n\nEpoch No: 10\n\n665477/665477 [==============================] - 473s 710us/sample - loss: 1.2521\n\n\t\t Generating text with seed: \"o meaning in the vedanta; that between two nations one is su\"\n\n\n\t\t Temperature:  0.2\no meaning in the vedanta; that between two nations one is superstition of the same truth is the same timeand the same of the mindand the practicalstateof the same man isthe same man is the man can be a thinks the same says, they are a thousand and the ideal ofthe sametime the same timebe the selfish says, there is a manis thesametruth is the same way to thesame way to be thesametime and and the same thinks and the same man was a manwho isth\n\n\t\t Temperature:  0.5\no meaning in the vedanta; that between two nations one is suppose we havea man is abrahman. itis the stars, and another, and abstract is thefinedis the priest with the universe, they haveto bethe infinite world restrationofthe mindof himself. they are to have to be the time only in theworldwill say that i have tobe like theotherthinks of the mind is really the changes to the perfectual internally so they are all the most power and theancien\n\n\t\t Temperature:  1.0\no meaning in the vedanta; that between two nations one is supdelsas iwantnot maynot take amar.he believing to dear forma was much intheteache it is it has think there, and all isa corratcist, andthat we are restor out and religion. responsibillchangerayis all bad mind. the enough of the philosophy of practical can beprimitabe misery. -lifes. thou art beyond that had draw the true arise and bigge; they have evilified about them, says on,deperi\n\n\t\t Temperature:  1.2\no meaning in the vedanta; that between two nations one is superiour? acted for me. it isa hes known not a wonderful neckhood; when they take but superstitionharmoncercestatheh;satisfies good. as the bigavali of uted me. a mall of karma-yogisof the variors nothing does notsays, anding arebad realise iross.  to so wanting, ready. they should you natural yogiss, \"pholookriyg of the gigaristed is tole practice. this are cohquleden other itself, mustshi\n\nEpoch No: 11\n\n665477/665477 [==============================] - 461s 693us/sample - loss: 1.2509\n\n\n\n\n\nEpoch No: 12\n\n665477/665477 [==============================] - 465s 698us/sample - loss: 1.2492\n\n\n\n\n\nEpoch No: 13\n\n665477/665477 [==============================] - 463s 696us/sample - loss: 1.2490\n\n\n\n\n\nEpoch No: 14\n\n665477/665477 [==============================] - 462s 695us/sample - loss: 1.2472\n\n\n\n\n\nEpoch No: 15\n\n555648/665477 [========================>.....] - ETA: 1:16 - loss: 1.2700"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-129f29a0292d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m41\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nEpoch No: %d\\n\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m#loss_values.append(hist.history['loss'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mstart_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmaxlen\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#loss_values = []\n",
    "for epoch in range(1, 41):\n",
    "    print(\"\\nEpoch No: %d\\n\" %(epoch))\n",
    "    model.fit(X, Y, batch_size=128, epochs=1)\n",
    "    #loss_values.append(hist.history['loss'])\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated_text = text[start_index: start_index + maxlen]\n",
    "    start_text = generated_text\n",
    "    if epoch%5==0:\n",
    "        print('\\n\\t\\t Generating text with seed: \\\"'+generated_text+'\\\"\\n')\n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        generated_text = start_text\n",
    "        if epoch%5==0:\n",
    "            print('\\n\\t\\t Temperature: ',temperature)\n",
    "            print(generated_text, end='')\n",
    "            model.save('text_gen_model.h5')\n",
    "        for i in range(400):\n",
    "            sampled = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(generated_text):\n",
    "                sampled[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = chars[next_index]\n",
    "\n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "            if epoch%5==0:\n",
    "                print(next_char, end='')\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595176631718",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}